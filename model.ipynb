{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Blackheads', 'Clear Skin', 'Cystic', 'Papules', 'Pustules', 'Rosacea', 'Whiteheads']\n",
      "Class 0 Weight: 2.6286\n",
      "Class 1 Weight: 2.9870\n",
      "Class 2 Weight: 1.4286\n",
      "Class 3 Weight: 0.5974\n",
      "Class 4 Weight: 1.2637\n",
      "Class 5 Weight: 0.4381\n",
      "Class 6 Weight: 1.1948\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nathan\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nathan\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ShuffleNet_V2_X0_5_Weights.IMAGENET1K_V1`. You can also use `weights=ShuffleNet_V2_X0_5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.8979\n",
      "Epoch 2/10, Loss: 1.6047\n",
      "Epoch 3/10, Loss: 1.1866\n",
      "Epoch 4/10, Loss: 0.9478\n",
      "Epoch 5/10, Loss: 0.7356\n",
      "Epoch 6/10, Loss: 0.5307\n",
      "Epoch 7/10, Loss: 0.3633\n",
      "Epoch 8/10, Loss: 0.3660\n",
      "Epoch 9/10, Loss: 0.2589\n",
      "Epoch 10/10, Loss: 0.2189\n",
      "Accuracy for class Blackheads: 75.00%\n",
      "Accuracy for class Clear Skin: 100.00%\n",
      "Accuracy for class Cystic: 6.67%\n",
      "Accuracy for class Papules: 86.49%\n",
      "Accuracy for class Pustules: 72.22%\n",
      "Accuracy for class Rosacea: 70.00%\n",
      "Accuracy for class Whiteheads: 88.89%\n",
      "Overall Test Accuracy: 72.08%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision import transforms, models\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Set up transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the full dataset\n",
    "full_dataset = datasets.ImageFolder(root=\"data/train\", transform=transform)\n",
    "\n",
    "# Create indices for training and testing split\n",
    "dataset_size = len(full_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.25, stratify=[full_dataset.targets[i] for i in indices])\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Checking the classes\n",
    "print(\"Classes:\", full_dataset.classes)\n",
    "\n",
    "# Define the augmentation function to place segments on random locations\n",
    "def place_segment_on_face(segment, canvas_size=(224, 224)):\n",
    "    # Create an empty canvas (you can change the background to simulate skin tones)\n",
    "    canvas = np.zeros((canvas_size[0], canvas_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Randomly pick a position to place the segment\n",
    "    x_offset = random.randint(0, canvas_size[0] - segment.shape[0])\n",
    "    y_offset = random.randint(0, canvas_size[1] - segment.shape[1])\n",
    "\n",
    "    # Place the segment on the canvas at the random location\n",
    "    canvas[x_offset:x_offset + segment.shape[0], y_offset:y_offset + segment.shape[1]] = segment\n",
    "    return canvas\n",
    "\n",
    "# Augmentation transformations for segment-based images (cheeks, nose, etc.)\n",
    "def augment_segment(segment):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),  # Convert to PIL image for augmentation\n",
    "        transforms.RandomRotation(15),  # Random rotation\n",
    "        transforms.RandomHorizontalFlip(),  # Horizontal flip\n",
    "        transforms.RandomVerticalFlip(),  # Vertical flip (if applicable)\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Random color tweak\n",
    "        transforms.RandomCrop(224),  # Random crop to simulate varying positions\n",
    "        transforms.ToTensor()  # Convert back to tensor\n",
    "    ])\n",
    "    return transform(segment)\n",
    "\n",
    "# Define a custom dataset that applies augmentation to segments\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, segmented_images, labels, transform=None):\n",
    "        self.segmented_images = segmented_images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segmented_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        segment = self.segmented_images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            segment = self.transform(segment)  # Apply the augmentation to each segment\n",
    "        \n",
    "        return segment, label\n",
    "\n",
    "# Calculate class weights using sklearn's compute_class_weight\n",
    "train_labels = [label for _, label in train_loader.dataset]  # Assuming labels are directly accessible from the dataset\n",
    "num_classes = len(set(train_labels))  # Number of classes (update as necessary)\n",
    "classes = np.array([i for i in range(num_classes)])  # Convert to numpy array for class indices\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=train_labels)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Print class names and their corresponding weights\n",
    "for i, weight in enumerate(class_weights):\n",
    "    print(f\"Class {i} Weight: {weight:.4f}\")\n",
    "\n",
    "# Load the pre-trained model and modify the final layer\n",
    "model = models.shufflenet_v2_x0_5(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the criterion (loss function) with class weights\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluation function to calculate per-class accuracy and overall accuracy\n",
    "def evaluate_per_class(model, test_loader):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Initialize a confusion matrix with zeros\n",
    "    conf_matrix = np.zeros((len(test_loader.dataset.dataset.classes), len(test_loader.dataset.dataset.classes)))\n",
    "\n",
    "    with torch.no_grad():  # No need to compute gradients during evaluation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)  # Send to device\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # Update confusion matrix\n",
    "            for t, p in zip(labels.view(-1), preds.view(-1)):\n",
    "                conf_matrix[t.item(), p.item()] += 1\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy for each class\n",
    "    class_accuracies = []\n",
    "    for i in range(len(test_loader.dataset.dataset.classes)):\n",
    "        class_correct = conf_matrix[i, i]\n",
    "        class_total = conf_matrix[i].sum()\n",
    "        class_accuracy = class_correct / class_total if class_total > 0 else 0\n",
    "        class_accuracies.append(class_accuracy)\n",
    "        print(f\"Accuracy for class {test_loader.dataset.dataset.classes[i]}: {class_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    accuracy = np.sum(np.diag(conf_matrix)) / np.sum(conf_matrix)\n",
    "    return accuracy, class_accuracies\n",
    "\n",
    "# Get the class-wise accuracy and overall accuracy\n",
    "overall_accuracy, class_accuracies = evaluate_per_class(model, test_loader)\n",
    "print(f\"Overall Test Accuracy: {overall_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model.pth\n"
     ]
    }
   ],
   "source": [
    "# Saving\n",
    "model_save_path = 'model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nathan\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Nathan\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Nathan\\AppData\\Local\\Temp\\ipykernel_17168\\1879304336.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    }
   ],
   "source": [
    "# Loading\n",
    "model = models.shufflenet_v2_x0_5(pretrained=False)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is classified as: Clear Skin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan\\AppData\\Local\\Temp\\ipykernel_10460\\568179294.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.pth'))  # Load the saved model weights\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Define the device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained model (make sure you have loaded the weights)\n",
    "model = models.shufflenet_v2_x0_5(pretrained=False)  # Use the model architecture you trained\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)  # Modify the final layer as needed\n",
    "model.load_state_dict(torch.load('model.pth'))  # Load the saved model weights\n",
    "model = model.to(device)  # Move the model to the correct device\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Replace 'your_image.jpg' with the path to the image you want to classify\n",
    "image_path = 'data/test/image.jpg'\n",
    "\n",
    "# Define the image transformations (resize, normalization) for model input\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 for the model\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = Image.open(image_path)\n",
    "image = transform(image).unsqueeze(0)  # Add a batch dimension (1, C, H, W)\n",
    "\n",
    "# Move the image tensor to the same device as the model\n",
    "image = image.to(device)\n",
    "\n",
    "# Perform inference (forward pass)\n",
    "with torch.no_grad():  # Disable gradient computation during inference\n",
    "    outputs = model(image)\n",
    "\n",
    "# Get the predicted class (index of the highest logit)\n",
    "_, predicted_class = torch.max(outputs, 1)\n",
    "\n",
    "# Access the classes from the original dataset (ImageFolder or similar)\n",
    "# Make sure to access the original dataset from train_loader (not the subset)\n",
    "classes = train_loader.dataset.dataset.classes  # Assuming your loader is a subset\n",
    "class_label = classes[predicted_class.item()]\n",
    "\n",
    "print(f\"The image is classified as: {class_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
